{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Classfier - TAP project\n",
    "### A real-time news article categorizer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduzione\n",
    "Lo scopo del progetto è quello di raccogliere e analizzare gli ultimissimi articoli giornalistici pubblicati ogni quindici minuti da più di 3000 testate in tutto il mondo, categorizzarli con un modello di machine learning sulla base del testo che li compone in una tra le diciassette categorie previste, ed infine mostrare i dati più rilevanti in una world-map dinamica stilizzata, permettendo inoltre analisi comparative tra i vari stati del mondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "<img src=\"./images/workflow.PNG\" width=90% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "Ogni tecnologia utilizzata in questa pipeline girerà all'interno di container opportunamente organizzati e gestiti tramite l'utilizzo del software Docker.\n",
    "\n",
    "<img src=\"./images/docker.png\" width=20% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Python daemon & GDELT Project\n",
    "GDELT è un progetto per l'acquisizione delle web news da quasi ogni angolo di ogni paese. Questo progetto si serve del servizio GDELT 2.0 da essi fornito nel ruolo di sorgente dati della pipeline. \\\n",
    "\\\n",
    "GDELT 2.0 fornisce periodicamente un file in formato CSV contenente dati sugli ultimissimi articoli di giornale pubblicati in tutto il mondo negli ultimi 15 minuti, da più di 3000 testate giornalistiche.\\\n",
    "Un demone python si occuperà di interrogare ogni 15 minuti il servizio, filtrando e riformattando oppurtunamente il dataframe. Dopodiché condivederà con Fluentd il file risultante, addormentandosi fino al prossimo update.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Fluentd\n",
    "Fluentd è un progetto software di raccolta dati open source multipiattaforma; i suoi punti forti sono sicuramente la leggerezza in termini di risorse utilizzate che sono ridotte ai minimi termini garantendo quindi anche una maggiore velocità ed il grande controllo interno (routing) dei flussi di dati.\\\n",
    "\\\n",
    "Fluentd condividerà un volume con il demone da cui verrano prelevati i dati grezzi. Questi verranno infine convogliati verso Kafka.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Apache Spark\n",
    "Apache Spark è un framework open source per il calcolo distribuito studiato appositamente per l'esecuzione di algoritmi di apprendimento automatico.\\\n",
    "\\\n",
    "Nel progetto si distinguono due istanze diverse di Spark; un trainer ed un executor.\\\n",
    "<b>Spark Trainer:</b> ha il compito di istruire un modello di machine learning per la classificazione di un testo in una tra le 17 categorie previste. Si serve di un dataset open opportunamente rielaborato ed adattato ai fini del progetto e nonostante la considerevole quantità di classi, grazie alle miracolose performance dell'algoritmo di NaiveBayes si dispone di una accuratezza del 74.5% su un dataset da circa 125.000 record.\\\n",
    "Le categorie sono le seguenti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| +--------------+\n",
      "| | category      |\n",
      "| +--------------+\n",
      "| | SPORTS\n",
      "| | POLITICS\n",
      "| | ENTERTAINMENT\n",
      "| | TECH\n",
      "| | CRIME\n",
      "| | BUSINESS\n",
      "| | STYLE & BEAUTY\n",
      "| | RELIGION\n",
      "| | EDUCATION\n",
      "| | ENVIRONMENT\n",
      "| | TRAVEL\n",
      "| | RIGHTS\n",
      "| | FOOD & DRINK\n",
      "| | ARTS & CULTURE\n",
      "| | WORLD NEWS\n",
      "| | SCIENCE\n",
      "| | WELLNESS\n",
      "\n",
      "There are: 17 classes.\n"
     ]
    }
   ],
   "source": [
    "category = [\"SPORTS\", \"POLITICS\", \"ENTERTAINMENT\", \"TECH\", \"CRIME\", \\\n",
    "            \"BUSINESS\", \"STYLE & BEAUTY\", \"RELIGION\", \"EDUCATION\", \\\n",
    "            \"ENVIRONMENT\", \"TRAVEL\", \"RIGHTS\", \"FOOD & DRINK\", \\\n",
    "            \"ARTS & CULTURE\", \"WORLD NEWS\", \"SCIENCE\", \"WELLNESS\"]\n",
    "\n",
    "print(\"| +--------------+\\n| | category      |\\n| +--------------+\")\n",
    "for words in category :\n",
    "    print(\"| |\", words)\n",
    "print(\"\\nThere are:\", len(category), \"classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Spark Exector:</b> si occuperà di applicare il modello addestrato al flusso di dati estratto da Kafka. Una volta processati i dati, applicando di fatto la classificazione, questi saranno indirizzati verso ElasticSearch.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Elastic Search & Kibana\n",
    "Elasticsearch è un server di ricerca con capacità Full Text e supporto ad architetture distribuite. Dal gennaio 2016 risulta essere il motore di ricerca più utilizzato in quanto può essere usato per cercare qualsiasi tipo di documento e fornisce un sistema di ricerca scalabile, quasi di tipo real-time, con supporto al multilatenancy.\\\n",
    "\\\n",
    "Viene utilizzato nel progetto come solida base alla costruzione di visualizzazioni grafiche e analisi dei dati con Kibana. Kibana è un software dashboard di visualizzazione e analisi dei dati disponibile in origine per Elasticsearch.\n",
    "\n",
    "\n",
    "<p style=\"font-size:18px;margin-bottom:-1px;color:#d1af5a\"><b>Dashboard:</b></p>\n",
    "<img src=\"./images/dashboard.png\" width=90% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<p style=\"font-size:18px;margin-bottom:-1px;color:#d1af5a\"><b>Geolocated iconed articles map, with detail:</b></p>\n",
    "<img src=\"./images/map-iconed-detail.png\" width=90% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<p style=\"font-size:18px;margin-bottom:-1px;color:#d1af5a\"><b>Gradient top crime count countries map:</b></p>\n",
    "<img src=\"./images/top crimes count map.png\" width=90% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "<p style=\"font-size:18px;margin-bottom:-1px;color:#d1af5a\"><b>Top category per country map</b></p>\n",
    "<img src=\"./images/top category per country map.png\" width=90% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memes\n",
    "\n",
    "<img src=\"./memes/photo_2023-07-25_23-44-17.jpg\" width=40% style=\"margin-top:auto;margin-left:auto; margin-right:auto\">\n",
    "<img src=\"./memes/photo_2023-07-25_23-44-11.jpg\" width=25% style=\"margin-left:auto; margin-right:auto\">\n",
    "<br>\n",
    "<img src=\"./memes/2023-07-25_23-45.png\" width=30% style=\"margin-left:auto; margin-right:auto\">\n",
    "<img src=\"./memes/photo_2023-07-25_23-43-52.jpg\" width=40% style=\"margin-left:auto; margin-right:auto\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
