# Boot order:
# zookeeper,kafkaserver,kafka-ui,daemon,elasticsearch,kafkaTopic => fluentd,sparkExecutor => kibana
  
  version: '3.7'

  services:

    #--- Kafka ---
    zookeeper:
        image: tap:kafka
        container_name: kafkaZk
        environment:
            - KAFKA_ACTION=start-zk
        networks: 
            tap:
                ipv4_address: 10.0.100.22
        deploy:
          resources:
            limits:
              cpus: '0.4'
              memory: 320m
        healthcheck:
          test: curl -f elasticsearch:9200 || exit 1
          interval: 30s
          retries: 20
          start_period: 30s

    kafkaserver:
        image: tap:kafka
        container_name: kafkaServer
        environment:
            - KAFKA_ACTION=start-kafka
            #- KAFKA_HEAP_OPTS=-Xmx256M
        ports:
            - 9092:9092
        networks: 
            tap:
                ipv4_address: 10.0.100.23
        restart: on-failure
        deploy:
          resources:
            limits:
              cpus: '0.5'
              memory: 500m


    kafkaTopic:
      image: tap:kafka
      container_name: kafkaTopic
      environment:
          - KAFKA_ACTION=create-topic
          - KAFKA_PARTITION=2
          - KAFKA_TOPIC=articles
      networks: 
          - tap
      deploy:
        resources:
          limits:
            cpus: '0.15'
            memory: 100m
      depends_on:
          kafkaserver:
            condition: service_started

    #--- fluentd ---
    fluentd:
      container_name: fluentd
      build:
        context: ./fluentd
        dockerfile: Dockerfile
      volumes:
        - ./fluentd/conf/prova.conf:/fluentd/etc/fluent.conf
        - dataframe:/fluentd/dataframe
      restart: on-failure
      networks:
        - tap
      depends_on:
          kafkaTopic:
            condition: service_completed_successfully
      deploy:
        resources:
          limits:
            cpus: '0.3'
            memory: 200m



    #--- ElasticSearch ---
    elasticsearch:
      container_name: elasticsearch
      hostname: elasticsearch
      image: docker.elastic.co/elasticsearch/elasticsearch:8.2.0
      ports:
        - "9200:9200"
        - "9300:9300"      
      environment:
        - node.name=elasticsearch
        - xpack.security.enabled=false
        - discovery.type=single-node
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
        - cluster.routing.allocation.disk.threshold_enabled=false
      restart: on-failure
      ulimits:
        memlock:
          soft: -1
          hard: -1
      networks: 
        - tap
      deploy:
        resources:
          limits:
            cpus: '0.65'
            memory: 1.9g


    #--- Kibana ---
    kibana:
      container_name: kibana
      hostname: kibana
      image: docker.elastic.co/kibana/kibana:8.2.0
      build: 
        context: kibana
        dockerfile: Dockerfile
      networks: 
        - tap
      ports:
        - 5601:5601
      environment:
        - xpack.security.enabled=false
      deploy:
        resources:
          limits:
            cpus: '0.4'
            memory: '800m'

  volumes:
    dataframe:
    training:
    sparklibs:

  networks:
    tap:
        name: tap
        driver: bridge
        ipam:
            config:
                - subnet: 10.0.100.1/24