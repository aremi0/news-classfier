# Boot order:
# elasticsearch,zookeeper,daemon,kafkaserver,kafkaUI,kafkaTopic => fluentd => sparkExecutor => kibana
  
  version: '3.7'

  services:

    #--- Kafka ---
    zookeeper:
      image: tap:kafka
      container_name: zookeeper
      environment:
          - KAFKA_ACTION=start-zk
      networks: 
          tap:
              ipv4_address: 10.0.100.22
      deploy:
        resources:
          limits:
            cpus: '0.5'
            memory: 320m

    kafkaserver:
      image: tap:kafka
      container_name: kafkaserver
      environment:
          - KAFKA_ACTION=start-kafka
          #- KAFKA_HEAP_OPTS=-Xmx256M
      ports:
          - 9092:9092
      networks: 
          tap:
              ipv4_address: 10.0.100.23
      restart: on-failure
      deploy:
        resources:
          limits:
            cpus: '0.6'
            memory: 500m

    kafka-ui:
        image: provectuslabs/kafka-ui:latest
        container_name: kafka-ui
        environment:
            - KAFKA_CLUSTERS_0_NAME=local
            - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafkaServer:9092
        ports: 
            - 8080:8080
        networks: 
            - tap
        depends_on:
            - kafkaserver
        deploy:
          resources:
            limits:
              cpus: '0.35'
              memory: 150m

    kafkaTopic:
      image: tap:kafka
      container_name: kafkaTopic
      environment:
          - KAFKA_ACTION=create-topic
          - KAFKA_PARTITION=2
          - KAFKA_TOPIC=articles
      networks: 
          - tap
      depends_on:
          - kafkaserver
      deploy:
        resources:
          limits:
            cpus: '0.15'
            memory: 100m

    #--- fluentd ---
    fluentd:
      container_name: fluentd
      build:
        context: ./fluentd
        dockerfile: Dockerfile
      volumes:
        - ./fluentd/conf/prova.conf:/fluentd/etc/fluent.conf
        - dataframe:/fluentd/dataframe
      restart: on-failure
      networks:
        - tap
      depends_on:
          kafkaTopic:
            condition: service_completed_successfully
      deploy:
        resources:
          limits:
            cpus: '0.2'
            memory: 250m
          
    #--- Daemon ---
    daemon:
      image: tap:daemon
      container_name: daemon
      environment:
        - PYTHONUNBUFFERED=1 # To let python print() be displayed. Comment to mute daemon
      networks:
        - tap
      volumes:
        - dataframe:/app/dataframe
      deploy:
        resources:
          limits:
            cpus: '0.2'
            memory: 200m

    #--- Spark ---  
    sparkExecutor:
      image: tap:sparkP
      container_name: sparkExecutor
      environment:
        - SPARK_ACTION=bash
      volumes:
        - training:/opt/tap/training
        - sparklibs:/root/.ivy2
      networks:
        - tap
      ports:
        - 4040:4040
      command: spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.elasticsearch:elasticsearch-spark-30_2.12:8.2.0 --master local[*] /opt/tap/executor.py
      depends_on:
        fluentd:
          condition: service_started
      deploy:
        resources:
          limits:
            cpus: '1.1'
            memory: 1.9g

    #--- ElasticSearch ---
    elasticsearch:
      container_name: elasticsearch
      hostname: elasticsearch
      image: docker.elastic.co/elasticsearch/elasticsearch:8.2.0
      ports:
        - "9200:9200"
        - "9300:9300"      
      environment:
        - node.name=elasticsearch
        - xpack.security.enabled=false
        - discovery.type=single-node
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
        - cluster.routing.allocation.disk.threshold_enabled=false
      restart: on-failure
      ulimits:
        memlock:
          soft: -1
          hard: -1
      networks: 
        - tap
      deploy:
        resources:
          limits:
            cpus: '1.3'
            memory: 1.9g

    #--- Kibana ---
    kibana:
      container_name: kibana
      hostname: kibana
      image: docker.elastic.co/kibana/kibana:8.2.0
      build: 
        context: kibana
        dockerfile: Dockerfile
      networks: 
        - tap
      ports:
        - 5601:5601
      environment:
        - xpack.security.enabled=false
      depends_on:
        sparkExecutor:
          condition: service_started
      deploy:
        resources:
          limits:
            cpus: '0.4'
            memory: 800m

  volumes:
    dataframe:
    training:
    sparklibs:

  networks:
    tap:
        name: tap
        driver: bridge
        ipam:
            config:
                - subnet: 10.0.100.1/24