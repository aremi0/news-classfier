# Boot order:
# zookeeper,kafkaserver,kafka-ui,daemon,elasticsearch,kafkaTopic,kibana => fluentd,sparkExecutor
  
  version: '3.7'

  services:

    #--- Kafka ---
    zookeeper:
        image: tap:kafka
        container_name: kafkaZk
        environment:
            - KAFKA_ACTION=start-zk
        networks: 
            tap:
                ipv4_address: 10.0.100.22
        deploy:
          resources:
            limits:
              cpus: '0.3'
              memory: 320m
        healthcheck:
          test: curl -f elasticsearch:9200 || exit 1
          interval: 30s
          retries: 20
          start_period: 30s

    kafkaserver:
        image: tap:kafka
        container_name: kafkaServer
        environment:
            - KAFKA_ACTION=start-kafka
            #- KAFKA_HEAP_OPTS=-Xmx256M
        ports:
            - 9092:9092
        networks: 
            tap:
                ipv4_address: 10.0.100.23
        restart: on-failure
        deploy:
          resources:
            limits:
              cpus: '0.3'
              memory: 500m


    kafkaTopic:
      image: tap:kafka
      container_name: kafkaTopic
      environment:
          - KAFKA_ACTION=create-topic
          - KAFKA_PARTITION=2
          - KAFKA_TOPIC=articles
      networks: 
          - tap
      deploy:
        resources:
          limits:
            cpus: '0.10'
            memory: 100m
      depends_on:
          kafkaserver:
            condition: service_started


    kafka-ui:
        image: provectuslabs/kafka-ui:latest
        container_name: kafkaWebUI
        environment:
            - KAFKA_CLUSTERS_0_NAME=local
            - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafkaServer:9092
        ports: 
            - 8080:8080
        networks: 
            - tap
        depends_on:
            kafkaserver:
              condition: service_started


    #--- fluentd ---
    fluentd:
      container_name: fluentd
      build:
        context: ./fluentd
        dockerfile: Dockerfile
      volumes:
        - ./fluentd/conf/prova.conf:/fluentd/etc/fluent.conf
        - dataframe:/fluentd/dataframe
      restart: on-failure
      networks:
        - tap
      depends_on:
          kafkaTopic:
            condition: service_completed_successfully
      deploy:
        resources:
          limits:
            cpus: '0.25'
            memory: 200m

    #--- Daemon ---
    daemon:
      image: tap:daemon
      container_name: daemon
      environment:
        - PYTHONUNBUFFERED=1 # To let python print() be displayed. Comment to mute daemon
      networks:
        - tap
      volumes:
        - dataframe:/app/dataframe
      deploy:
        resources:
          limits:
            cpus: '0.7'
            memory: 500m

    #--- ElasticSearch ---
    elasticsearch:
      container_name: elasticsearch
      hostname: elasticsearch
      image: docker.elastic.co/elasticsearch/elasticsearch:8.2.0
      ports:
        - "9200:9200"
        - "9300:9300"      
      environment:
        - node.name=elasticsearch
        - xpack.security.enabled=false
        - discovery.type=single-node
        - bootstrap.memory_lock=true
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
        - cluster.routing.allocation.disk.threshold_enabled=false
      restart: on-failure
      ulimits:
        memlock:
          soft: -1
          hard: -1
      networks: 
        - tap
      deploy:
        resources:
          limits:
            cpus: '0.5'
            memory: 1.9g


    #--- Spark ---  
    sparkExecutor:
      image: tap:sparkP
      container_name: sparkExecutor
      environment:
        - SPARK_ACTION=bash
      volumes:
        - training:/opt/tap/training
        - sparklibs:/root/.ivy2
      networks:
        - tap
      ports:
        - 4040:4040
      command: spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.elasticsearch:elasticsearch-spark-30_2.12:8.2.0 --master local[*] /opt/tap/executor.py
      deploy:
        resources:
          limits:
            cpus: '0.5'
            memory: 1.9g
      depends_on:
          kafkaTopic:
            condition: service_completed_successfully
          zookeeper:
            condition: service_healthy


    #--- Kibana ---
    kibana:
      container_name: kibana
      hostname: kibana
      image: docker.elastic.co/kibana/kibana:8.2.0
      build: 
        context: kibana
        dockerfile: Dockerfile
      networks: 
        - tap
      ports:
        - 5601:5601
      environment:
        - xpack.security.enabled=false
      deploy:
        resources:
          limits:
            cpus: '0.3'
            memory: '800m'

  volumes:
    dataframe:
    training:
    sparklibs:

  networks:
    tap:
        name: tap
        driver: bridge
        ipam:
            config:
                - subnet: 10.0.100.1/24